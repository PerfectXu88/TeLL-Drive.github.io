<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Papers and Videos</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f0f2f5;
            color: #333;
        }
        header {
            background: linear-gradient(135deg, #3a3f44, #009688);
            color: #fff;
            padding: 4rem 4rem;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }
        header h1 {
            margin: 1.5rem 0;
            font-weight: 700;
            font-size: 2.4rem;
        }
        .github-button {
            display: inline-block;
            background-color: #333;
            color: #fff;
            padding: 0.8rem 1.5rem;
            border-radius: 5px;
            text-decoration: none;
            font-weight: 700;
            transition: background-color 0.3s ease;
            margin-top: 2rem;
        }
        .github-button:hover {
            background-color: #555;
        }
        .container {
            max-width: 900px;
            margin: 2rem auto;
            padding: 2rem;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .section {
            margin-bottom: 2rem;
        }
        .section h2 {
            color: #3a3f44;
            text-align: center;
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }
        .section p {
            line-height: 1.8;
            font-size: 1rem;
            color: #555;
        }
        .authors {
            display: flex;
            justify-content: center;
            gap: 1.5rem;
            flex-wrap: wrap;
            margin-bottom: 1.5rem;
        }
        .authors a {
            color: #3a3f44;
            text-decoration: none;
            font-weight: 700;
            transition: color 0.3s ease;
        }
        .authors a:hover {
            color: #0056b3;
        }
        .images img {
            max-width: 100%;
            border-radius: 8px;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .images h3 {
            font-size: 1.0rem;
            color: #555;
            text-align: left;
            margin-top: 0.5rem;
        }
        video {
            width: 100%;
            height: auto;
            border-radius: 8px;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .video h3 {
            font-size: 1.5rem;
            color: #555;
            text-align: center;
            margin-top: 1.5rem;
        }
        .video h4 {
            font-size: 1.0rem;
            color: #555;
            text-align: left;
            margin-top: 1.5rem;
        }
    </style>
</head>
<body>
    <header>
        <h1>TeLL-Drive: Enhancing Autonomous Driving with</h1>
        <h1>Teacher LLM-Guided Deep Reinforcement Learning</h1>
        <a href="https://github.com/PerfectXu88/TeLL-Drive.github.io" class="github-button" target="_blank">
            View on GitHub
        </a>
    </header>
    <div class="container">
        <div class="section info">
            <div class="authors">
                <a href="https://perfectxu88.github.io/" target="_blank">Chengkai Xu</a>
                <a href="https://jiaqiliu-aca.netlify.app/" target="_blank">Jiaqi Liu</a>
                <a href="https://fangshiyuu.github.io/" target="_blank">Shiyu Fang</a>
                <a href="https://tops.tongji.edu.cn/info/1131/1818.htm" target="_blank">Yiming Cui</a>
                <a href="https://tops.tongji.edu.cn/info/1031/1383.htm" target="_blank">Peng Hang</a>
            </div>
        </div>
        <div class="section abstract">
            <h2>Abstract</h2>
            <p>
                Although Deep Reinforcement Learning (DRL) and Large Language Models (LLMs) each show promise in addressing decision-making challenges in autonomous driving, DRL often suffers from high sample complexity, while LLMs have difficulty ensuring real-time decision making. To address these limitations, we propose TeLL-Drive, a hybrid framework that integrates an Teacher LLM to guide an attention-based Student DRL policy. By incorporating risk metrics, historical scenario retrieval, and domain heuristics into context-rich prompts, the LLM produces high-level driving strategies through chain-of-thought reasoning. A self-attention mechanism then fuses these strategies with the DRL agent’s exploration, accelerating policy convergence and boosting robustness across diverse driving conditions. Our experimental results, evaluated across multiple traffic scenarios, show that TeLL-Drive outperforms existing baseline methods, including other LLM-based approaches, in terms of success rates, average returns, and real-time feasibility. Ablation studies underscore the importance of each model component, especially the synergy between the attention mechanism and LLM-driven guidance. Finally, we build a virtual-real fusion experimental platform to verify the real-time, robustness, and reliability of the model when deployed in real vehicles through vehicle-in-loop experiments. These findings suggest that TeLL-Drive significantly enhances both the adaptability and safety of autonomous driving systems, while offering a more efficient and scalable approach for policy learning.
            </p>
        </div>
        <div class="section images">
            <h2>Images</h2>
            <img src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/framework.png?raw=true" alt="The overview of the proposed data-model-knowledge hybrid-driven framework for self-organizing autonomous vehicle platooning.">
            <h3>The overall conceptual framework of TeLL-Drive, where a DRL student agent is guided by the LLM teacher for better decision making in autonomous driving.</h3>
            <img src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/scenario.png?raw=true" alt="Illustration of the considered traffic scenario and the solution. CAVs (Red) and HDVs (Green) are both considered.">
            <h3>Illustration of the considered traffic scenario and the solution. CAVs (Red) and HDVs (Green) are both considered.</h3>
            <img src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/Reward.png?raw=true" alt="Illustration of the designed headway maintaining reward, which considers both the single-vehicle rewards and the multi-vehicle rewards.">
            <h3>Illustration of the designed headway maintaining reward, which considers both the single-vehicle rewards and the multi-vehicle rewards.</h3>
        </div>
        <div class="section video">
            <h2>Videos</h2>
            <h3>SIL experiment</h3>
            <h4>The model has been trained in a multitude of scenarios, and the following illustration demonstrates the model's performance in SIL with the selected training results from three typical high-risk scenarios.</h4>
            <h4>The risk factors encountered are: human interference, traffic accidents and fluctuations in traffic flow.</h4>
            <video controls>
                <source src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/S - human interference.mp4?raw=true" type="video/mp4">
            </video>
            <video controls>
                <source src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/S - traffic accidents.mp4?raw=true" type="video/mp4">
            </video>
            <video controls>
                <source src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/S - fluctuations in traffic flow.mp4?raw=true" type="video/mp4">
            </video>
            <h3>HIL experiment</h3>
            <h4>We build a HIL experimental platform and conduct HIL experiments to further test and verify the model's safety and robustness.</h4>
            <video controls>
                <source src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/freecompress-H - human interference.mp4?raw=true" type="video/mp4">
            </video>
            <h4>In the first scenario, the platoon encounters a severe static obstruction: a multi-vehicle collision blocking multiple lanes.</h4>
            <h4>Our model resolves this complex situation through adaptive decision-making, avoiding secondary collisions by allowing the first vehicle to initiate a lane change and the other vehicles to follow once adequate space is available.</h4>
            <video controls>
                <source src="https://github.com/PerfectXu88/towardssafeandrobust.github.io/blob/main/freecompress-H - traffic accidents.mp4?raw=true" type="video/mp4">
            </video>
            <h4>In the second scenario, the platoon faces a dynamic obstruction: the leading vehicle decelerates suddenly at 5 m/s² due to a breakdown.</h4>
            <h4>Our model effectively coordinates lane changes and vehicle positioning, leading to a smooth reformation of the platoon with optimal efficiency.</h4>
        </div>
    </div>
</body>
</html>
